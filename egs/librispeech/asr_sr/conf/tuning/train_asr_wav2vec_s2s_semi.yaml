batch_type: folded
batch_size: 1
accum_grad: 8
max_epoch: 50
patience: none
# The initialization method for model parameters
init: xavier_uniform
best_model_criterion:
-   - valid
    - acc
    - max
keep_nbest_models: 10

input_size: 2048

encoder: wav2vec2
encoder_conf:
    output_size: 1024
    apply_mask: true
    mask_prob: 0.5
    mask_channel_prob: 0.5
    mask_channel_length: 64
    layerdrop: 0.1
    activation_dropout: 0.1
    feature_grad_mult: 0.0
    freeze_finetune_updates: 0
    pretrained_model: false
    normalize_before: false
    w2v_url: https://dl.fbaipublicfiles.com/fairseq/wav2vec/libri960_big.pt
    w2v_dir_path: ./download/wav2vec_pretrained_models

decoder: rnn
decoder_conf:
    rnn_type: lstm
    num_layers: 2
    hidden_size: 1024
    sampling_probability: 0.0
    att_conf:
        atype: location
        adim: 1024
        awin: 5
        aheads: 1
        aconv_chans: 10
        aconv_filts: 100

model_conf:
    ctc_weight: 0.3
    lsm_weight: 0.1
    length_normalized_loss: false

optim: adam
optim_conf:
    lr: 0.00003
scheduler: warmuplr
scheduler_conf:
    warmup_steps: 25000

unused_parameters: true
frontend: null
normalize: null
specaug: null

# Label Refurbishment Mode Selection
# Choices: [pseudo, gradient_masking, recursive_gradient_masking, bootstrap]
semi_mode: gradient_masking
